{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4e4e5-d05c-46ac-8bf8-6222df71eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "YT_URL=\"https://www.youtube.com/watch?v=tOdpaSh6C1A\" #\"https://www.youtube.com/watch?v=1xdV2j02uW4\"\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    YT_URL, language=[\"en\", \"es\", \"de\"], translation=\"es\", add_video_info=True,\n",
    ")\n",
    "\n",
    "transcript = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a002b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript[0].metadata\n",
    "\n",
    "video_metadata = dict(**transcript[0].metadata)\n",
    "video_metadata.update({\"transcript\": transcript[0].page_content})\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "doc = Document(page_content=video_metadata[\"transcript\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b77c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8: noqa\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "templ1 = \"\"\"You are a highly intelligent and insightful assistant designed to generate high-quality multiple-choice quiz questions. Your task is to read the provided text, identify key information, and create a corresponding question with four possible answersâ€”one correct answer and three plausible but incorrect alternatives.\n",
    "\n",
    "Each question and its associated answers should be:\n",
    "1. **Clear and concise**: Ensure that both the question and the answers are easy to understand, well-formulated, and free from ambiguity.\n",
    "2. **Engaging and challenging**: The incorrect answers should be plausible enough to make the quiz engaging, requiring thoughtful consideration by the user.\n",
    "3. **Relatively short**: Answers should be brief, typically no more than a sentence.\n",
    "4. **Appropriately aligned with the specified difficulty level**: Ensure the generated questions match the intended difficulty. For **easy quizzes**, the questions should focus on basic, easily recognizable information with straightforward answers. For **medium quizzes**, questions should involve more complex topics requiring a deeper understanding or application of the subject. For **hard quizzes**, craft questions that require critical thinking, analysis, or interpretation of nuanced information. The incorrect options should be particularly convincing, making the quiz genuinely challenging at this level.\n",
    "\n",
    "When generating these question-answer pairs, follow this format:\n",
    "\n",
    "```\n",
    "{{\n",
    "\"question\": \"$YOUR_QUESTION_HERE\",\n",
    "\"answer\": {{\"correct_answer\": \"$THE_CORRECT_ANSWER_HERE\", \"wrong_answers\": [\"$THE_FIRST_WRONG_ANSWER_HERE\",\"$THE_SECOND_WRONG_ANSWER_HERE\",\"$THE_THIRD_WRONG_ANSWER_HERE\"]}}\n",
    "}}\n",
    "```\n",
    "\n",
    "Everything between the ``` must be valid JSON, make sure there are no whitespaces or special characters in the output so that it can be parsed to JSON!\n",
    "\n",
    "Here is an example of how to extract question/answers from a given text:\n",
    "> Given Text:\n",
    "\"Albert Einstein developed the theory of relativity, one of the two pillars of modern physics. His work also laid the foundation for the development of quantum mechanics.\"\n",
    "> Generated question and answers:\n",
    "\"question\": \"Who developed the theory of relativity?\",\n",
    "\"correct_answer\": \"Albert Einstein\",\n",
    "\"wrong_answers\": [\"Isaac Newton\",\"Niels Bohr\",\"Marie Curie\"]\n",
    "> Additionally, the question/answers should be formated to JSON format as stated above.\n",
    "\n",
    "You still have to parse the question and answers into a valid JSON as provided above!\n",
    "\n",
    "\"\"\"\n",
    "templ2 = \"\"\"The quiz questions should be of difficulty. Please come up with question/answers pair in JSON format from the following given text: #### {diff} ###\n",
    "----------------\n",
    "{text}\"\"\"\n",
    "\n",
    "def get_prompt(diff):\n",
    "    return ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(templ1),\n",
    "            HumanMessagePromptTemplate.from_template(templ2, partial_variables={\"diff\": diff})\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "get_prompt(\"EASY\").format(text=\"HI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(), override=True)\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Write a concise summary of the following text and in the same language:\n",
    "    \"{text}\"\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm_chain = LLMChain(llm=ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o-mini\",\n",
    "), prompt=prompt)\n",
    "\n",
    "llm_chain.run(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481408f-cf85-46a8-92a6-f8bd86a43b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.qa_generation.base import QAGenerationChain\n",
    "\n",
    "from json import JSONDecodeError\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(), override=True)\n",
    "\n",
    "import itertools\n",
    "import uuid\n",
    "import sys\n",
    "from pathlib import Path\n",
    "    \n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(Path.cwd())\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"POSTGRES_DRIVER\"] = \"psycopg\"\n",
    "os.environ[\"POSTGRES_HOST\"]=\"localhost\"\n",
    "os.environ[\"POSTGRES_PORT\"]=\"5432\"\n",
    "os.environ[\"POSTGRES_DATABASE\"] = \"quizstream_db\"\n",
    "os.environ[\"POSTGRES_USER\"] = \"admin\"\n",
    "os.environ[\"POSTGRES_PASSWORD\"] = \"my_password\"\n",
    "\n",
    "def chunk_transcript(doc: Document) -> list[Document]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=len(doc.page_content) // 7,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "\n",
    "    # add end_index\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata[\"end_index\"] = chunk.metadata[\"start_index\"] + len(\n",
    "            chunk.page_content\n",
    "        )\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def get_qa_from_chunk(\n",
    "    chunk: Document,\n",
    "    qa_generator_chain: QAGenerationChain,\n",
    ") -> list[dict]:\n",
    "    try:\n",
    "        # return list of qa pairs\n",
    "        qa_pairs = qa_generator_chain.run(chunk.page_content)\n",
    "\n",
    "        # attach chunk metadata to qa_pair\n",
    "        for qa_pair in qa_pairs:\n",
    "            qa_pair[\"metadata\"] = dict(**chunk.metadata)\n",
    "            qa_pair[\"metadata\"].update(\n",
    "                {\"id\": str(uuid.uuid4()), \"context\": chunk.page_content}\n",
    "            )\n",
    "\n",
    "        return qa_pairs\n",
    "\n",
    "    except JSONDecodeError:\n",
    "        return [-1]\n",
    "\n",
    "def generate_qa_from_transcript(transcript: Document) -> list[dict[str, str]]:\n",
    "\n",
    "    chunks = chunk_transcript(transcript)\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    qa_chain = QAGenerationChain.from_llm(llm, prompt=QA_GENERATION_PROMPT)\n",
    "\n",
    "    qa_pairs = [get_qa_from_chunk(chunk, qa_chain) for chunk in chunks]\n",
    "    qa_pairs = list(itertools.chain.from_iterable(qa_pairs))\n",
    "\n",
    "    return qa_pairs\n",
    "\n",
    "#data = generate_qa_from_transcript(transcript[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c52f1-7b57-4484-9613-4e5470328590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53a63c-5945-4fa5-8f71-2cfd801dc117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.quiz_generation.generator import agenerate_quiz\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(), override=True)\n",
    "\n",
    "col_metadata, qa_ids = await agenerate_quiz(\"my_xyz_quiz\",\n",
    "                                YT_URL,\n",
    "                                {\"OPENAI_API_KEY\": os.environ.get(\"OPENAI_API_KEY\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162688fd-a19d-492c-8211-df5a9515a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ab2bb-88f7-4d95-bd06-749fe0934945",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8debfa-cdbc-41f0-abf7-62e342d835c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection_string = \"postgresql+psycopg://postgres:pwd@localhost:5432/quizzes\"  # Uses psycopg3!\n",
    "collection_name = \"my_docs\"\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from langchain_core.embeddings import FakeEmbeddings\n",
    "embeddings = FakeEmbeddings(size=1)\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection_string,\n",
    "    use_jsonb=True,\n",
    "    collection_metadata={\"date_created\": dt.datetime.now(dt.UTC).strftime('%Y-%m-%dT%H:%M:%SZ'), 'num_tries': 1, 'acc':0.2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724500e-03c2-40f8-a1dc-90e88f50591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name+\"+\",\n",
    "    connection=connection_string,\n",
    "    use_jsonb=True,\n",
    "    collection_metadata={\"date_created\": dt.datetime.now(dt.UTC).strftime('%Y-%m-%dT%H:%M:%SZ'), 'num_tries': 1, 'acc':0.2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3533c5f-bef9-4ed3-b91e-45078c0935cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.uui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3432181-4ecc-4f1c-8706-7e6829526c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(page_content=\"hello\", metadata={'a':1, 'id':1}),\n",
    "        Document(page_content=\"hello2\", metadata={'a':2, 'id':2})]\n",
    "vector_store.add_documents(docs,\n",
    "                          ids=[doc.metadata[\"id\"] for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c868c-1f25-4252-85bc-c1364803263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "\n",
    "TABLE_COLLECTION = \"langchain_pg_collection\"\n",
    "TABLE_DOCS = \"langchain_pg_embedding\"\n",
    "\n",
    "def list_collections() -> list[str]:\n",
    "    # Create an engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Reflect the specific table\n",
    "    metadata = MetaData()\n",
    "    table = Table(TABLE_COLLECTION, metadata, autoload_with=engine)\n",
    "\n",
    "    # Query the column\n",
    "    query = select(table.c[\"name\"])\n",
    "    with engine.connect() as connection:\n",
    "        results = connection.execute(query).fetchall()\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_by_ids(ids: list[str]) -> list[str]:\n",
    "    # Create an engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Reflect the specific table\n",
    "    metadata = MetaData()\n",
    "    table = Table(TABLE_DOCS, metadata, autoload_with=engine)\n",
    "\n",
    "    # Query the column\n",
    "    query = select(table).where(table.c.id.in_(ids))\n",
    "    with engine.connect() as connection:\n",
    "        results = connection.execute(query).fetchall()\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_all_by_collection_id(engine:Engine, collection_id: str):\n",
    "\n",
    "    # Reflect the specific table\n",
    "    table = Table(TABLE_DOCS, MetaData(), autoload_with=engine)\n",
    "\n",
    "    # Query the column\n",
    "    query = select(table).where(table.c.collection_id == collection_id)\n",
    "    with engine.connect() as connection:\n",
    "        results = connection.execute(query).fetchall()\n",
    "\n",
    "    return results\n",
    "\n",
    "list_collections(), get_by_ids([\"aad30221-cdc1-4add-86db-f4067ee9d8c7\"]), get_all_by_collection_id(engine, \"994272b7-354d-4c98-9c92-8d4b23b60e62\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a5fad-82c5-4d42-8407-83febf15dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_collection_metadata(engine, \"994272b7-354d-4c98-9c92-8d4b23b60e62\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42423340-f7f8-413b-a35a-fa841b3eb869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751c71f-3f26-4275-a380-614dca9fb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, HttpUrl, field_validator\n",
    "import re\n",
    "\n",
    "\n",
    "class QuizRequest(BaseModel):\n",
    "    quiz_name: str = Field(min_length=3, description=\"Name of quiz\")\n",
    "    user_id: str = Field(min_length=1, description=\"User id\")\n",
    "    api_keys: dict[str, str] = Field(description=\"Dictionary of API keys.\")\n",
    "    youtube_url: HttpUrl\n",
    "\n",
    "    @field_validator(\"youtube_url\")\n",
    "    @classmethod\n",
    "    def validate_youtube_url(cls, value: HttpUrl) -> HttpUrl:\n",
    "\n",
    "        youtube_regex = (\n",
    "            r\"(https?://)?(www\\.)?\"\n",
    "            r\"(youtube|youtu|youtube-nocookie)\\.(com|be)/\"\n",
    "            r\"(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})\"\n",
    "        )\n",
    "\n",
    "        youtube_pattern = re.compile(youtube_regex)\n",
    "\n",
    "        if not youtube_pattern.match(str(value)):\n",
    "            raise ValueError(\"Invalid YouTube video URL\")\n",
    "\n",
    "        return value\n",
    "\n",
    "\n",
    "q = QuizRequest(quiz_name=\"abc\", user_id=\"1\", api_keys={'a':'b'}, youtube_url='http://www.youtube.com/watch?v=ruauz315oms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
