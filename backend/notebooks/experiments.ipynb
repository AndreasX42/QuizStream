{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a4e4e5-d05c-46ac-8bf8-6222df71eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "YT_URL= \"https://www.youtube.com/watch?v=IFx8eABfivg\"\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    YT_URL, language=[\"en\", \"es\", \"de\"], translation=\"de\", add_video_info=True,\n",
    ")\n",
    "\n",
    "transcript = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(), override=True)\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Write a concise and simple explanation of the following error message in a way that is easily understandable by someone without a technical background. \n",
    "\n",
    "If there was a problem with transcript retrieval of youtube video, add warning that app only supports given list of languages. \n",
    "\n",
    "Focus on the key issue and avoid technical terms:\n",
    "    \"{text}\"\n",
    "CONCISE SUMMARY (limit to one or two sentences):\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm = llm=ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "doc = Document(page_content=msg2)\n",
    "\n",
    "summarizing_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "summarizing_chain.invoke(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481408f-cf85-46a8-92a6-f8bd86a43b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.qa_generation.base import QAGenerationChain\n",
    "\n",
    "import itertools\n",
    "import uuid\n",
    "import sys\n",
    "from pathlib import Path\n",
    "    \n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(Path.cwd())\n",
    "\n",
    "from json import JSONDecodeError\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(), override=True)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"POSTGRES_DRIVER\"] = \"psycopg\"\n",
    "os.environ[\"POSTGRES_HOST\"]=\"localhost\"\n",
    "os.environ[\"POSTGRES_PORT\"]=\"5432\"\n",
    "os.environ[\"POSTGRES_DATABASE\"] = \"quizstream_db\"\n",
    "os.environ[\"POSTGRES_USER\"] = \"admin\"\n",
    "os.environ[\"POSTGRES_PASSWORD\"] = \"my_password\"\n",
    "\n",
    "def chunk_transcript(doc: Document) -> list[Document]:\n",
    "        \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=len(doc.page_content) // 7,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "\n",
    "    # add end_index\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata[\"end_index\"] = chunk.metadata[\"start_index\"] + len(\n",
    "            chunk.page_content\n",
    "        )\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def get_qa_from_chunk(\n",
    "    chunk: Document,\n",
    "    qa_generator_chain: QAGenerationChain,\n",
    ") -> list[dict]:\n",
    "    try:\n",
    "        # return list of qa pairs\n",
    "        qa_pairs = qa_generator_chain.run(chunk.page_content)\n",
    "\n",
    "        # attach chunk metadata to qa_pair\n",
    "        for qa_pair in qa_pairs:\n",
    "            qa_pair[\"metadata\"] = dict(**chunk.metadata)\n",
    "            qa_pair[\"metadata\"].update(\n",
    "                {\"id\": str(uuid.uuid4()), \"context\": chunk.page_content}\n",
    "            )\n",
    "\n",
    "        return qa_pairs\n",
    "\n",
    "    except JSONDecodeError:\n",
    "        return [-1]\n",
    "\n",
    "def generate_qa_from_transcript(transcript: Document) -> list[dict[str, str]]:\n",
    "\n",
    "    chunks = chunk_transcript(transcript)\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    qa_chain = QAGenerationChain.from_llm(llm, prompt=get_qa_prompt(difficulty=\"HARD\", language=\"EN\", num_attempt=1))\n",
    "\n",
    "    qa_pairs = [get_qa_from_chunk(chunk, qa_chain) for chunk in chunks]\n",
    "    qa_pairs = list(itertools.chain.from_iterable(qa_pairs))\n",
    "\n",
    "    return qa_pairs\n",
    "\n",
    "data = generate_qa_from_transcript(transcript[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53a63c-5945-4fa5-8f71-2cfd801dc117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.quiz_generation.generator import agenerate_quiz\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(), override=True)\n",
    "\n",
    "col_metadata, qa_ids = await agenerate_quiz(\"my_xyz_quiz\",\n",
    "                                YT_URL,\n",
    "                                {\"OPENAI_API_KEY\": os.environ.get(\"OPENAI_API_KEY\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8debfa-cdbc-41f0-abf7-62e342d835c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection_string = \"postgresql+psycopg://postgres:pwd@localhost:5432/quizzes\"  # Uses psycopg3!\n",
    "collection_name = \"my_docs\"\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from langchain_core.embeddings import FakeEmbeddings\n",
    "embeddings = FakeEmbeddings(size=1)\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection_string,\n",
    "    use_jsonb=True,\n",
    "    collection_metadata={\"date_created\": dt.datetime.now(dt.UTC).strftime('%Y-%m-%dT%H:%M:%SZ'), 'num_tries': 1, 'acc':0.2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c868c-1f25-4252-85bc-c1364803263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "\n",
    "TABLE_COLLECTION = \"langchain_pg_collection\"\n",
    "TABLE_DOCS = \"langchain_pg_embedding\"\n",
    "\n",
    "def list_collections() -> list[str]:\n",
    "    # Create an engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Reflect the specific table\n",
    "    metadata = MetaData()\n",
    "    table = Table(TABLE_COLLECTION, metadata, autoload_with=engine)\n",
    "\n",
    "    # Query the column\n",
    "    query = select(table.c[\"name\"])\n",
    "    with engine.connect() as connection:\n",
    "        results = connection.execute(query).fetchall()\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_by_ids(ids: list[str]) -> list[str]:\n",
    "    # Create an engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Reflect the specific table\n",
    "    metadata = MetaData()\n",
    "    table = Table(TABLE_DOCS, metadata, autoload_with=engine)\n",
    "\n",
    "    # Query the column\n",
    "    query = select(table).where(table.c.id.in_(ids))\n",
    "    with engine.connect() as connection:\n",
    "        results = connection.execute(query).fetchall()\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_all_by_collection_id(engine:Engine, collection_id: str):\n",
    "\n",
    "    # Reflect the specific table\n",
    "    table = Table(TABLE_DOCS, MetaData(), autoload_with=engine)\n",
    "\n",
    "    # Query the column\n",
    "    query = select(table).where(table.c.collection_id == collection_id)\n",
    "    with engine.connect() as connection:\n",
    "        results = connection.execute(query).fetchall()\n",
    "\n",
    "    return results\n",
    "\n",
    "list_collections(), get_by_ids([\"aad30221-cdc1-4add-86db-f4067ee9d8c7\"]), get_all_by_collection_id(engine, \"994272b7-354d-4c98-9c92-8d4b23b60e62\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
